{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting GitHub sync...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching starred repos: 1pages [00:02,  2.30s/pages, total=68]\n",
      "Fetching curated lists: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n",
      "Processing starred repos:  16%|█▌        | 11/68 [00:05<00:29,  1.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 212\u001b[39m\n\u001b[32m    209\u001b[39m         sys.exit(\u001b[32m1\u001b[39m)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 195\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    194\u001b[39m repo_tags, ignore_repos = get_curated_tags()\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m starred_df = \u001b[43mprocess_starred_repositories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstarred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_repos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m uploaded = upload_to_motherduck(starred_df, \u001b[33m\"\u001b[39m\u001b[33mstarred\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Uploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muploaded\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m starred repositories\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mprocess_starred_repositories\u001b[39m\u001b[34m(repos, repo_tags, ignore_repos)\u001b[39m\n\u001b[32m    123\u001b[39m owner, repo_name = full_name.split(\u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    124\u001b[39m last_release = get_last_release_date(owner, repo_name)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m topics = \u001b[43mget_repo_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mowner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m curated_tags = \u001b[38;5;28mlist\u001b[39m(repo_tags.get(full_name, \u001b[38;5;28mset\u001b[39m()))\n\u001b[32m    127\u001b[39m all_tags = topics + curated_tags\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mget_repo_topics\u001b[39m\u001b[34m(owner, repo)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_repo_topics\u001b[39m(owner, repo):\n\u001b[32m    113\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://api.github.com/repos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mowner\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/topics\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     resp = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtopics_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m resp.json().get(\u001b[33m'\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m'\u001b[39m, []) \u001b[38;5;28;01mif\u001b[39;00m resp.status_code == \u001b[32m200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m.iter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\urllib3\\response.py:1252\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1251\u001b[39m chunk = \u001b[38;5;28mself\u001b[39m._handle_chunk(amt)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m decoded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_decoder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1254\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n\u001b[32m   1256\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m decoded\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\urllib3\\response.py:510\u001b[39m, in \u001b[36mBaseHTTPResponse._decode\u001b[39m\u001b[34m(self, data, decode_content, flush_decoder)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder:\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28mself\u001b[39m._has_decoded_content = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m.DECODER_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Repos\\evidence_test\\.venv\\Lib\\site-packages\\urllib3\\response.py:111\u001b[39m, in \u001b[36mGzipDecoder.decompress\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         ret += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m zlib.error:\n\u001b[32m    113\u001b[39m         previous_state = \u001b[38;5;28mself\u001b[39m._state\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Unified GitHub Repository Sync\n",
    "Combines starred repository fetching and recommendation generation\n",
    "Simplified: no descriptions, only essential fields\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import duckdb\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# GitHub Lists (slug-only format)\n",
    "GITHUB_LISTS = [\n",
    "    \"stack\",\n",
    "    \"nice-to-have\",\n",
    "    \"future-ideas\",\n",
    "    \"ignore\"\n",
    "]\n",
    "\n",
    "load_dotenv()\n",
    "GHUB_TOKEN = os.getenv('GHUB_TOKEN')\n",
    "MOTHERDUCK_TOKEN = os.getenv('MOTHERDUCK_TOKEN')\n",
    "MOTHERDUCK_DB = os.getenv('MOTHERDUCK_DB', 'github')\n",
    "\n",
    "BASE_LIST_URL = \"https://github.com/stars/Veatec22/lists/\"\n",
    "\n",
    "auth_headers = {\n",
    "    'Authorization': f'token {GHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "topics_headers = {\n",
    "    'Authorization': f'token {GHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.mercy-preview+json'\n",
    "}\n",
    "\n",
    "def get_motherduck_connection():\n",
    "    try:\n",
    "        conn_str = f\"md:{MOTHERDUCK_DB}\"\n",
    "        if MOTHERDUCK_TOKEN:\n",
    "            conn_str += f\"?motherduck_token={MOTHERDUCK_TOKEN}\"\n",
    "        return duckdb.connect(conn_str)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error connecting to MotherDuck: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_starred_repos():\n",
    "    starred = []\n",
    "    page = 1\n",
    "    with tqdm(desc=\"Fetching starred repos\", unit=\"pages\") as pbar:\n",
    "        while True:\n",
    "            resp = requests.get(\n",
    "                'https://api.github.com/user/starred',\n",
    "                headers=auth_headers,\n",
    "                params={'per_page': 100, 'page': page}\n",
    "            )\n",
    "            if resp.status_code != 200:\n",
    "                print(f\"Error fetching starred repos: {resp.status_code}\")\n",
    "                break\n",
    "            data = resp.json()\n",
    "            if not data:\n",
    "                break\n",
    "            starred.extend(data)\n",
    "            page += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(total=len(starred))\n",
    "    return starred\n",
    "\n",
    "def scrape_github_list(slug):\n",
    "    url = BASE_LIST_URL + slug\n",
    "    try:\n",
    "        resp = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        if resp.status_code != 200:\n",
    "            return []\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "        blocks = soup.select('div#user-list-repositories > div.border-bottom')\n",
    "        return [a['href'].strip('/') for b in blocks if (a := b.select_one('h3 a'))]\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error scraping {slug}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def get_curated_tags():\n",
    "    repo_tags = defaultdict(set)\n",
    "    ignore_repos = set()\n",
    "    for slug in tqdm(GITHUB_LISTS, desc=\"Fetching curated lists\"):\n",
    "        repos = scrape_github_list(slug)\n",
    "        if slug == \"ignore\":\n",
    "            ignore_repos.update(repos)\n",
    "        else:\n",
    "            for r in repos:\n",
    "                repo_tags[r].add(slug)\n",
    "        time.sleep(1)\n",
    "    return repo_tags, ignore_repos\n",
    "\n",
    "def get_last_release_date(owner, repo):\n",
    "    url = f'https://api.github.com/repos/{owner}/{repo}/releases/latest'\n",
    "    resp = requests.get(url, headers=auth_headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json().get(\"published_at\")\n",
    "    elif resp.status_code == 404:\n",
    "        return \"No releases\"\n",
    "    return f\"Error: {resp.status_code}\"\n",
    "\n",
    "def get_repo_topics(owner, repo):\n",
    "    url = f'https://api.github.com/repos/{owner}/{repo}/topics'\n",
    "    resp = requests.get(url, headers=topics_headers)\n",
    "    return resp.json().get('names', []) if resp.status_code == 200 else []\n",
    "\n",
    "def process_starred_repositories(repos, repo_tags, ignore_repos):\n",
    "    data = []\n",
    "    for repo in tqdm(repos, desc=\"Processing starred repos\"):\n",
    "        full_name = repo['full_name']\n",
    "        if full_name in ignore_repos:\n",
    "            continue\n",
    "        owner, repo_name = full_name.split('/')\n",
    "        last_release = get_last_release_date(owner, repo_name)\n",
    "        topics = get_repo_topics(owner, repo_name)\n",
    "        curated_tags = list(repo_tags.get(full_name, set()))\n",
    "        all_tags = topics + curated_tags\n",
    "        data.append({\n",
    "            'name': full_name,\n",
    "            'stars': repo['stargazers_count'],\n",
    "            'language': repo.get('language', 'Unknown'),\n",
    "            'url': repo['html_url'],\n",
    "            'last_release': last_release,\n",
    "            'curated_tags': \", \".join(sorted(curated_tags)),\n",
    "            'all_tags': \", \".join(sorted(all_tags)),\n",
    "            'is_curated': len(curated_tags) > 0\n",
    "        })\n",
    "        time.sleep(0.1)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_recommendations(starred_df, ignore_repos, min_stars=1000, max_per_topic=50):\n",
    "    all_topics = []\n",
    "    starred_names = set(starred_df['name'])\n",
    "    for tags in starred_df['all_tags']:\n",
    "        all_topics.extend([t.strip().lower() for t in tags.split(',') if t.strip()])\n",
    "    topic_counter = Counter(all_topics)\n",
    "    if not topic_counter:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    recommendations = {}\n",
    "    for topic, _ in tqdm(topic_counter.most_common(), desc=\"Searching topics\"):\n",
    "        params = {\n",
    "            'q': f\"topic:{topic} stars:>={min_stars}\",\n",
    "            'sort': 'stars',\n",
    "            'order': 'desc',\n",
    "            'per_page': min(max_per_topic, 100),\n",
    "            'page': 1\n",
    "        }\n",
    "        try:\n",
    "            resp = requests.get('https://api.github.com/search/repositories', headers=auth_headers, params=params)\n",
    "            if resp.status_code != 200:\n",
    "                continue\n",
    "            for repo in resp.json().get('items', []):\n",
    "                if repo['full_name'] in starred_names or repo['full_name'] in ignore_repos:\n",
    "                    continue\n",
    "                recommendations[repo['id']] = {\n",
    "                    'name': repo['full_name'],\n",
    "                    'stars': repo['stargazers_count'],\n",
    "                    'language': repo.get('language', 'Unknown'),\n",
    "                    'url': repo['html_url']\n",
    "                }\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error searching for topic '{topic}': {e}\")\n",
    "    return pd.DataFrame(recommendations.values()).sort_values('stars', ascending=False)\n",
    "\n",
    "def upload_to_motherduck(df, table_name):\n",
    "    try:\n",
    "        conn = get_motherduck_connection()\n",
    "        conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        conn.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM df\")\n",
    "        return conn.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error uploading to MotherDuck: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    print(\"🚀 Starting GitHub sync...\")\n",
    "    try:\n",
    "        starred = get_starred_repos()\n",
    "        if not starred:\n",
    "            print(\"⚠️ No starred repositories found\")\n",
    "            return\n",
    "        repo_tags, ignore_repos = get_curated_tags()\n",
    "        starred_df = process_starred_repositories(starred, repo_tags, ignore_repos)\n",
    "        uploaded = upload_to_motherduck(starred_df, \"starred\")\n",
    "        print(f\"✅ Uploaded {uploaded} starred repositories\")\n",
    "\n",
    "        recs_df = generate_recommendations(starred_df, ignore_repos)\n",
    "        if not recs_df.empty:\n",
    "            uploaded_recs = upload_to_motherduck(recs_df, \"recommendations\")\n",
    "            print(f\"✅ Uploaded {uploaded_recs} recommendations\")\n",
    "        else:\n",
    "            print(\"⚠️ No recommendations generated\")\n",
    "\n",
    "        print(\"🎉 GitHub sync completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
